{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e63ba7-d2ba-49fc-82b9-b52987934008",
   "metadata": {},
   "outputs": [],
   "source": [
    "from denoiser.data.source import AudioSource\n",
    "from denoiser.data.dataset import AudioDataset\n",
    "from denoiser.data.collate import collate\n",
    "from denoiser.data.augmentations.default import get_default_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b254e258-7dcb-48f4-badc-f45e354ad08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "noise_folder = Path(\"/data/denoising/noise/records/DEMAND/48k\")\n",
    "train_augments = get_default_augmentation(sequence_length_s=0.0, split='train', p=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6aa610-284b-44b8-aa03-9be1f5ce7e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "sr = 24_000\n",
    "speech_folder = Path(\"/data/denoising/speech/daps/clean\")\n",
    "train_audio_source = AudioSource(\n",
    "    speech_folder / \"index.train.json\",\n",
    "    sequence_length_s=64 / 75,\n",
    ")\n",
    "train_dataset = AudioDataset(\n",
    "    train_audio_source,\n",
    "    sample_rate=sr,\n",
    "    augmentation=train_augments,\n",
    ")\n",
    "train_dloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=1,\n",
    "    collate_fn=collate,\n",
    "    num_workers=0,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9642c4-9fa5-45c7-8f96-ec84ca1c6bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dloader = iter(train_dloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a923c6-1ca1-4482-9941-22701b3491f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(dloader)\n",
    "print(batch.augmentation_params)\n",
    "clean = batch.waveforms\n",
    "noisy = train_augments.augment(clean, parameters=batch.augmentation_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d34851-0c7c-47cf-8a06-e48fa7a69c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Audio\n",
    "\n",
    "display(Audio(clean[0].numpy(), rate=sr))\n",
    "display(Audio(noisy[0].numpy(), rate=sr))\n",
    "# display(Audio(noise[0].numpy(), rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c368d0-5e92-4d29-80f4-63cb825bfe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from denoiser.data.audio import Audio\n",
    "from denoiser.models.codec.dac import DescriptAudioCodec\n",
    "\n",
    "from IPython.display import Audio as AudioPlayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eeac87-5778-4d8f-9a1f-de81b34d1e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "codec = \"dac\"\n",
    "\n",
    "if codec == \"mimi\":\n",
    "    codec = MimiCodec(\n",
    "        \"/home/lucas/models/moshi/tokenizer-e351c8d8-checkpoint125.safetensors\"\n",
    "    )\n",
    "elif codec == \"dac\":\n",
    "    codec = DescriptAudioCodec(\"/data/models/dac/weights_24khz_8kbps_0.0.4.pth\")\n",
    "codec = codec.eval()\n",
    "codec = codec.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9daad0-dc6d-42f3-9a4a-85064476a310",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = Audio(\"/data/denoising/speech/daps/clean/f10_script1_clean.wav\")\n",
    "audio.resample(codec.sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c910e5-f222-44da-ac1d-5d1494b7f724",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    reconstructed = codec.decode(codec.encode(audio.waveform[None].to(device)))\n",
    "    # reconstructed = codec.reconstruct(audio.waveform[None].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92309d60-70af-4b95-9881-ccbc4da4df9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "AudioPlayer(audio.waveform, rate=codec.sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d026edd-db8a-4944-afad-ea28ca9566a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "AudioPlayer(reconstructed[0].cpu(), rate=codec.sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227dce90-3d30-4d3c-a5a9-5c37227cd789",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    encoded = codec.encode(audio.waveform[None].to(device))\n",
    "    nencoded = codec.normalize(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687b15ee-f7f3-4a42-ab1e-fae09efde133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(0.5 * nencoded[0].std(-1).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe69740d-8340-42ba-955f-51f59e9964df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from denoiser.models.cfm.cfm import ConditionalFlowMatcher\n",
    "\n",
    "cfm = ConditionalFlowMatcher(nn.Identity())\n",
    "print(cfm.sigma_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dadcdc-693c-495f-b973-f901d0081411",
   "metadata": {},
   "outputs": [],
   "source": [
    "nencoded.std(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa512d56-fc39-4acd-b2e5-6eed03921d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0 = 0.5 * torch.randn_like(nencoded)\n",
    "xs, lls, ss = [], [], []\n",
    "for t in torch.linspace(0, 1, 100):\n",
    "    with torch.inference_mode():\n",
    "        sigma_t = cfm.sigma_t(t)\n",
    "        x_t = sigma_t * x_0 + t * nencoded\n",
    "        xs.append(x_t.cpu())\n",
    "        lls.append(N.log_prob(x_t).exp())\n",
    "        ss.append(sigma_t)\n",
    "xs = torch.cat(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8543bac-4f2d-4ba0-ba8b-f163747b13a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = (255 / 5 * xs).int()\n",
    "xs.min(), xs.max(), xs.numpy().dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e1f6ab-a7fa-4a15-ba96-1e7ce3ad568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "gif = [Image.fromarray(x) for x in xs.cpu().numpy().astype(np.int8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08332071-8dd9-4750-8047-a941c810c851",
   "metadata": {},
   "outputs": [],
   "source": [
    "gif[0].save(\"array.gif\", save_all=True, append_images=gif[1:], duration=15, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddfea84-cc46-4ad2-adc2-f08af0730c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "gif[0].save('gif.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd89503b-37b3-4ccf-b311-434431145d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(xs[0].cpu().numpy(), aspect='auto')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25fc649-f20d-4c42-b8be-1c5699520dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs.cpu().numpy().astype(np.int8).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1738077-fbfa-4320-adc2-338bf47ac85e",
   "metadata": {},
   "source": [
    "![SegmentLocal](array.gif \"segment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d44782e-6120-4730-bdb1-b099ef64a591",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(xs.std(-1).T, aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc61de8-e6af-49ba-99e8-79016ac26b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.plot(xs.std(-1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c07495b-e963-404e-9184-7520674c313d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Normal\n",
    "\n",
    "N = Normal(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d91df63-9867-4bce-bf47-4b669018a627",
   "metadata": {},
   "outputs": [],
   "source": [
    "N.log_prob(nencoded).exp().mean(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a179b0e-0413-40ee-bbe2-c554da3e403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N.log_prob(torch.randn_like(xs[0])).exp().mean(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966ebe11-9203-4ce8-8796-cdeaa1dc8885",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.plot(torch.cat(lls).cpu().mean(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d2e980-4582-401a-b2db-3f6f60b68658",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack(lls).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279006dc-6b75-44bd-93ae-eb7c7d7fb8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(xs[0], aspect='auto')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af45970-9460-433c-af32-d0f707a03861",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(nencoded.cpu()[0], aspect='auto')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c673337c-898c-4f81-99b9-9bea7804983f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(torch.stack(ss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d9834a-e1d8-4fd2-a4e9-dd2026d11777",
   "metadata": {},
   "outputs": [],
   "source": [
    "nencoded.mean(), nencoded.std(), x_0.mean(), x_0.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c530c3-612d-4e9d-b042-d80fb035cf0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
