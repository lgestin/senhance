{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, math\n",
    "\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Audio as AudioPlayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from senhance.models.codec.dac import DescriptAudioCodec\n",
    "\n",
    "codec = DescriptAudioCodec('/data/models/dac/weights_24khz_8kbps_0.0.4.pth').to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from senhance.models.checkpoint import Checkpoint\n",
    "from senhance.models.cfm.cfm import ConditionalFlowMatcher\n",
    "from senhance.models.unet.unet import UNET1d, UNET1dDims\n",
    "\n",
    "checkpoint = Checkpoint.load('/data/experiments/test2/checkpoint.25000.pt')\n",
    "dims = UNET1dDims(codec.dim, 1024, 1024)\n",
    "unet = UNET1d(dims)\n",
    "# unet = torch.compile(unet)\n",
    "cfm = ConditionalFlowMatcher(unet)\n",
    "cfm.load_state_dict(checkpoint.model)\n",
    "cfm = cfm.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from senhance.data.audio import Audio\n",
    "\n",
    "x = Audio(\"/data/denoising/speech/ljspeech/LJSpeech-1.1/wavs/LJ001-0001.wav\")\n",
    "x = x.resample(24_000)\n",
    "seq_length = 64 / codec.resolution_hz\n",
    "excerpt = x.normalize(-24.0).salient_excerpt(seq_length)\n",
    "AudioPlayer(excerpt.waveform.numpy(), rate=excerpt.sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from senhance.data.augmentations.default import get_default_augmentation\n",
    "\n",
    "augment = get_default_augmentation(noise_folder='/data/denoising/noise/', sample_rate=x.sample_rate, sequence_length_s=1, split=\"test\", p=1.0)\n",
    "augment_params = augment.sample_parameters(excerpt)\n",
    "augmented = augment.augment(excerpt.waveform[None].clone(), augment_params)\n",
    "AudioPlayer(augmented[0], rate=excerpt.sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    augmented = augmented.to(device)\n",
    "    z_nsy = codec.normalize(codec.encode(augmented.clone()))\n",
    "    timesteps = torch.linspace(1, math.exp(1), 20).log()\n",
    "    z_hat = cfm.sample(z_nsy.clone(), timesteps.tolist())\n",
    "    denoised = codec.decode(codec.unnormalize(z_hat.clone())).cpu().numpy()\n",
    "AudioPlayer(denoised[0], rate=excerpt.sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    z_cln = codec.normalize(codec.encode(excerpt.waveform[None].clone().to('cuda'))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(z_cln - z_hat).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist((z_cln-z_hat).detach().cpu().view(-1), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = 2.5\n",
    "fig = plt.figure(figsize=(10, 15))\n",
    "axs = fig.subplots(3)\n",
    "axs[0].imshow(z_cln[0].detach().cpu(), aspect='auto', interpolation='none', vmin=-v, vmax=v)\n",
    "axs[0].set_title('clean')\n",
    "axs[1].imshow(z_nsy[0].detach().cpu(), aspect='auto', interpolation='none', vmin=-v, vmax=v)\n",
    "axs[1].set_title('noisy')\n",
    "axs[2].imshow(z_hat[0].detach().cpu(), aspect='auto', interpolation='none', vmin=-v, vmax=v)\n",
    "axs[2].set_title('denoised')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 15))\n",
    "plt.imshow((z_hat - z_cln).abs()[0].detach().cpu(), aspect='auto', interpolation='none', vmin=-v, vmax=v)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(z_nsy.detach().cpu().view(-1), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
